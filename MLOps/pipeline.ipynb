{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"raNPOGvDTZS6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d41996a3-15e9-4681-af52-e2335e14f242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting catboost\n","  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting eli5\n","  Downloading eli5-0.13.0.tar.gz (216 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (23.2.0)\n","Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (3.1.4)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5) (1.2.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5) (0.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n","Building wheels for collected packages: eli5\n","  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107720 sha256=697713f60b3679516501c0b5bfb136ea0cfab03e8deaa8998e22608c4a29adf3\n","  Stored in directory: /root/.cache/pip/wheels/b8/58/ef/2cf4c306898c2338d51540e0922c8e0d6028e07007085c0004\n","Successfully built eli5\n","Installing collected packages: eli5, catboost\n","Successfully installed catboost-1.2.5 eli5-0.13.0\n"]}],"source":["! pip install catboost eli5"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"O9RZOE3aTvyw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cca685cc-da06-4a6b-fc69-5965669d76bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import datetime as dt\n","import re\n","from sklearn.preprocessing import StandardScaler\n","from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","from dateutil.relativedelta import relativedelta\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from lightgbm import LGBMClassifier\n","import pickle\n","from xgboost import XGBClassifier\n","from hyperopt.early_stop import no_progress_loss\n","from catboost import CatBoostClassifier, Pool\n","from sklearn.linear_model import SGDClassifier\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"_m2NPJslVBB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 본인 환경에 맞게 경로 수정\n","path = '/content/drive/MyDrive/python/2024-1학기/MLOps/project/data/'\n","df = pd.read_csv(path+'data.csv', encoding= 'cp1252')"],"metadata":{"id":"pRAc0wqIT3pO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DropOutlier(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        pass\n","\n","    def is_numeric(self, text):\n","        return text.isdigit()\n","\n","    def has_multiple_words(self, text):\n","        return len(text.split()) > 1\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        X = X.loc[X['InvoiceNo'].apply(self.is_numeric)]\n","        X = X.loc[(X['Quantity'] > 0) & (X['Quantity'] <= 100)]\n","        X.loc[:, 'Description'] = X.loc[:, 'Description'].astype(str)\n","        X = X.loc[(X['Description'].apply(self.has_multiple_words)) |\n","                  (X['Description'].isin(['SOMBRERO', 'POSTAGE', 'CARRIAGE']))]\n","        X = X.reset_index(drop=True)\n","        X = X.drop(columns=['StockCode']).drop_duplicates()\n","        return X\n","\n","\n","class FeatureEngineering(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        X = X.copy()\n","        X['InvoiceDate'] = pd.to_datetime(X['InvoiceDate'])\n","        X['InvoiceDate'] = X['InvoiceDate'].dt.date\n","        X = X.sort_values(by=['CustomerID', 'InvoiceDate'])\n","        X['Total_Price'] = X['Quantity'] * X['UnitPrice']\n","        X = X.groupby(['CustomerID', 'InvoiceDate']).agg({\n","            'Quantity': ['sum', 'min', 'max'],\n","            'UnitPrice': ['median', 'min', 'max'],\n","            'Total_Price': ['sum', 'mean', 'min', 'max']\n","        }).reset_index()\n","        X.columns = ['{}_{}'.format(col[0], col[1]) if col[1] else col[0] for col in X.columns]\n","        X['InvoiceDate'] = pd.to_datetime(X['InvoiceDate'])\n","        X['Quantity'] = X['Quantity_sum']\n","        X['Total_Price'] = X['Total_Price_sum']\n","        X['UnitPrice'] = X['UnitPrice_median']\n","        X.drop(columns=['Quantity_sum', 'Total_Price_sum', 'UnitPrice_median'], inplace=True)\n","\n","        X['past_purchases'] = X.groupby('CustomerID').cumcount()\n","        X['past_purchase'] = np.where(X['past_purchases'] != 0, 1, X['past_purchases'])\n","        X['days_since_last_purchase'] = X.groupby('CustomerID')['InvoiceDate'].diff().dt.days\n","        X['days_since_last_purchase'] = X['days_since_last_purchase'].fillna(0).astype(int)\n","        X['days_since_last_purchase Expanding Mean'] = X.groupby(['CustomerID'])['days_since_last_purchase'].transform(\n","            lambda x: x.shift().expanding().mean()).fillna(0)\n","        X['first_purchase_date'] = X.groupby('CustomerID')['InvoiceDate'].transform('min')\n","        X['days_since_first_purchase'] = (X['InvoiceDate'] - X['first_purchase_date']).dt.days\n","        X.drop(columns='first_purchase_date', inplace=True)\n","        X['UnitPrice Expanding Mean'] = X.groupby(['CustomerID'])['UnitPrice'].transform(\n","            lambda x: x.shift().expanding().mean()).fillna(0)\n","        X['past_total_price'] = X.groupby('CustomerID')['Total_Price'].cumsum() - X['Total_Price']\n","        X['Total_Price Expanding Mean'] = X.groupby(['CustomerID'])['Total_Price'].transform(\n","            lambda x: x.shift().expanding().mean()).fillna(0)\n","\n","        X['next_purchase_date'] = X.groupby('CustomerID')['InvoiceDate'].shift(-1)\n","        X['time_difference'] = (X['next_purchase_date'] - X['InvoiceDate']).dt.days\n","        X['Churn'] = np.where(X['time_difference'].isna(), np.nan, np.where(X['time_difference'] > 90, 1, 0))\n","        X.drop(columns=['time_difference', 'next_purchase_date'], inplace=True)\n","        X['time_difference'] = (X['InvoiceDate'].max() - X['InvoiceDate']).dt.days\n","        X['Churn'] = np.where((X.Churn.isna()) & (X['time_difference'] > 90), 1, X.Churn)\n","        X.drop(columns=['time_difference'], inplace=True)\n","        X['past_churns'] = X.groupby('CustomerID')['Churn'].cumsum() - X['Churn']\n","        X['past_churns'] = X.groupby('CustomerID')['past_churns'].ffill().fillna(0)\n","        X['past_churn'] = np.where(X['past_churns'] != 0, 1, X['past_churns'])\n","        X['churn_lag1'] = X.groupby('CustomerID')['Churn'].shift(1).fillna(0)\n","\n","        X['UnitPrice_amplitude'] = X['UnitPrice'] - X['UnitPrice Expanding Mean']\n","        X['Total_Price_amplitude'] = X['Total_Price'] - X['Total_Price Expanding Mean']\n","\n","        return X\n","\n","class DropFeature(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        X = X.copy()\n","        X.drop(columns=['Quantity', 'past_churns', 'CustomerID'], inplace=True)\n","\n","        return X\n","\n","\n","class CatPipeline(BaseEstimator, TransformerMixin):\n","    def __init__(self, now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30,hyperparameters=False):\n","        self.now_timestamp = now_timestamp\n","        self.churn_day = churn_day\n","        self.test_size = test_size\n","        self.pred_size = pred_size\n","        self.foldnum = foldnum\n","        self.jump_day = jump_day\n","        self.selected_features = None\n","        self.metrics_list = []\n","        self.all_fold_importances = []\n","        self.preprocessed_data = None\n","        self.hyperparameters = hyperparameters\n","\n","        self.model = None\n","        self.train_pred = None\n","        self.test_pred = None\n","\n","        self.final_model = None\n","        self.final_train_pred = None\n","        self.final_test_pred = None\n","\n","    def make_train_test_pred(self, data, now_timestamp, churn_day=90, test_size=30, pred_size=7):\n","        test_timestamp = pd.Timestamp(now_timestamp) - relativedelta(days=churn_day)\n","        train_timestamp = pd.Timestamp(test_timestamp) - relativedelta(days=churn_day)\n","        train = data[data['InvoiceDate'] <= train_timestamp].sort_values(by='InvoiceDate')\n","        test = data[(data['InvoiceDate'] > (test_timestamp - relativedelta(days=test_size))) &\n","                    (data['InvoiceDate'] <= test_timestamp)].sort_values(by='InvoiceDate')\n","        pred = data[(data['InvoiceDate'] > pd.Timestamp(now_timestamp) - relativedelta(days=pred_size)) &\n","                    (data['InvoiceDate'] <= pd.Timestamp(now_timestamp))].sort_values(by='InvoiceDate')\n","        final_train = data[data['InvoiceDate'] <= test_timestamp].sort_values(by='InvoiceDate')\n","        return train, test, pred, final_train\n","\n","    def make_validation_timestamp(self, data, now_timestamp, foldnum=4, jump_day=30):\n","        validation_timestamps = []\n","        now_timestamp = pd.Timestamp(now_timestamp)\n","        for i in range(foldnum):\n","            now_timestamp -= relativedelta(days=jump_day)\n","            validation_timestamps.append(now_timestamp.date().strftime('%Y-%m-%d'))\n","        return sorted(validation_timestamps)\n","\n","    def calculate_permutation_importance(self, model, X_valid, y_valid):\n","        perm = PermutationImportance(model, scoring='f1', random_state=0)\n","        perm.fit(X_valid, y_valid)\n","        return perm.feature_importances_\n","\n","    def preprocess(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering()),\n","            ('drop_feature', DropFeature())\n","        ])\n","        self.preprocessed_data = pipeline.fit_transform(X)\n","        return self.preprocessed_data\n","\n","    def preprocess_nodrop(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering())\n","\n","        ])\n","        self.preprocessed_data_nodrop = pipeline.fit_transform(X)\n","        return self.preprocessed_data_nodrop\n","\n","\n","\n","    def select_features(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","\n","        for timestamp in fold_timestamp:\n","            print('---', timestamp, 'fold----------------------')\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            print('train 시작 시점 :', train.iloc[0]['InvoiceDate'])\n","            print('train 마지막 시점 :', train.iloc[-1]['InvoiceDate'])\n","            print('valid 시작 시점 :', valid.iloc[0]['InvoiceDate'])\n","            print('valid 마지막 시점 :', valid.iloc[-1]['InvoiceDate'])\n","            print('\\n')\n","\n","            X_train = train.drop(columns=['Churn', 'InvoiceDate'])\n","            y_train = train.Churn\n","            X_test = valid.drop(columns=['Churn', 'InvoiceDate'])\n","            y_test = valid.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, iterations=100, eval_metric='F1', class_weights=[1, 10], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","            cm = confusion_matrix(y_test, y_pred)\n","\n","            self.metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","            importances = self.calculate_permutation_importance(model, X_test, y_test)\n","            self.all_fold_importances.append(importances)\n","\n","        total_weight = sum(fold_weights)\n","        weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        weighted_importances = np.average(self.all_fold_importances, axis=0, weights=fold_weights)\n","        feature_importances = pd.Series(weighted_importances, index=feature_names).sort_values(ascending=False)\n","        self.selected_features = feature_importances.loc[feature_importances.values > 0].index.to_list()\n","\n","        print(\"Weighted averages of validation sets (recent folds weighted more):\")\n","        print(f\"Weighted Accuracy: {weighted_avg['accuracy']:.4f}\")\n","        print(f\"Weighted AUC: {weighted_avg['auc']:.4f}\")\n","        print(f\"Weighted F1-score: {weighted_avg['f1']:.4f}\")\n","        print(f\"Weighted Precision: {weighted_avg['precision']:.4f}\")\n","        print('\\n')\n","\n","        plt.figure(figsize=(6, 4))\n","        feature_importances.plot(kind='barh')\n","        plt.title('Weighted Permutation Importances')\n","        plt.xlabel('Features')\n","        plt.ylabel('Importance')\n","        plt.gca().invert_yaxis()\n","        plt.show()\n","        print('\\n')\n","\n","\n","\n","        return self.selected_features\n","\n","\n","    def train_with_selected_features(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","        new_metrics_list = []\n","\n","        for timestamp in fold_timestamp:\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = valid[self.selected_features]\n","            y_test = valid.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, iterations=100, eval_metric='F1', class_weights=[1, 10], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            new_metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","        total_weight = sum(fold_weights)\n","        final_weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        self.final_metrics_0 = final_weighted_avg\n","\n","        print(\"------Final weighted averages of validation sets with selected features (recent folds weighted more)------\",'\\n')\n","\n","        print(f\"Final Weighted Accuracy: {final_weighted_avg['accuracy']:.4f}\")\n","        print(f\"Final Weighted AUC: {final_weighted_avg['auc']:.4f}\")\n","        print(f\"Final Weighted F1-score: {final_weighted_avg['f1']:.4f}\")\n","        print(f\"Final Weighted Precision: {final_weighted_avg['precision']:.4f}\")\n","        print('\\n\\n')\n","\n","        return self.final_metrics_0\n","\n","    def train_with_selected_hyperparameters(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","        new_metrics_list = []\n","\n","        for timestamp in fold_timestamp:\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = valid[self.selected_features]\n","            y_test = valid.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, depth = 10, l2_leaf_reg = 20,random_strength=20, iterations=100, eval_metric='F1', class_weights=[1, 7], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            new_metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","        total_weight = sum(fold_weights)\n","        final_weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        self.final_metrics_1 = final_weighted_avg\n","\n","        print(\"------Final weighted averages of validation sets with selected features and hyperparameters (recent folds weighted more)------\",'\\n')\n","\n","        print(f\"Final Weighted Accuracy: {final_weighted_avg['accuracy']:.4f}\")\n","        print(f\"Final Weighted AUC: {final_weighted_avg['auc']:.4f}\")\n","        print(f\"Final Weighted F1-score: {final_weighted_avg['f1']:.4f}\")\n","        print(f\"Final Weighted Precision: {final_weighted_avg['precision']:.4f}\")\n","\n","        return self.final_metrics_1\n","\n","    def final_train(self):\n","        train, test, pred, final_train = self.make_train_test_pred(self.preprocessed_data, self.now_timestamp, self.churn_day, self.test_size, self.pred_size)\n","        print('\\n')\n","        print('---------Final Model Train---------')\n","        print('\\n')\n","        print('train 시작 시점 :', train.iloc[0]['InvoiceDate'])\n","        print('train 마지막 시점 :', train.iloc[-1]['InvoiceDate'])\n","        print('test 시작 시점 :', test.iloc[0]['InvoiceDate'])\n","        print('test 마지막 시점 :', test.iloc[-1]['InvoiceDate'])\n","        print('pred 시작 시점 :', pred.iloc[0]['InvoiceDate'])\n","        print('pred 마지막 시점 :', pred.iloc[-1]['InvoiceDate'])\n","        print('\\n')\n","\n","\n","        if self.hyperparameters == False:\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, iterations=100, eval_metric='F1', class_weights=[1, 10], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Test Accuracy: { accuracy:.4f}\")\n","            print(f\"Final Test AUC: {auc:.4f}\")\n","            print(f\"Final Test F1-score: {f1:.4f}\")\n","            print(f\"Final Test Precision: {precision:.4f}\")\n","\n","        if self.hyperparameters == True:\n","          if self.final_metrics_0['f1'] < self.final_metrics_1['f1']:\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, depth = 10, l2_leaf_reg = 20,random_strength=20, iterations=100, eval_metric='F1', class_weights=[1, 7], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Test Accuracy: { accuracy:.4f}\")\n","            print(f\"Final Test AUC: {auc:.4f}\")\n","            print(f\"Final Test F1-score: {f1:.4f}\")\n","            print(f\"Final Test Precision: {precision:.4f}\")\n","\n","          else:\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            cat_features = [i for i in range(len(X_train.columns)) if X_train.dtypes.iloc[i] == 'object']\n","\n","            train_pool = Pool(data=X_train.values, label=y_train.values, feature_names=feature_names, cat_features=cat_features)\n","            test_pool = Pool(data=X_test.values, label=y_test.values, feature_names=feature_names, cat_features=cat_features)\n","\n","            model = CatBoostClassifier(random_seed=0, iterations=100, eval_metric='F1', class_weights=[1, 10], verbose=0)\n","            model.fit(train_pool)\n","\n","            y_pred = model.predict(test_pool)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Test Accuracy: { accuracy:.4f}\")\n","            print(f\"Final Test AUC: {auc:.4f}\")\n","            print(f\"Final Test F1-score: {f1:.4f}\")\n","            print(f\"Final Test Precision: {precision:.4f}\")\n","\n","        self.model = model\n","        self.train_pred =  model.predict_proba(train_pool)\n","        self.test_pred = model.predict_proba(test_pool)\n","\n","        X_tmp = final_train[self.selected_features]\n","        y_tmp = final_train.Churn\n","\n","        X_pred = pred[self.selected_features]\n","\n","\n","        feature_names = X_tmp.columns.to_list()\n","        cat_features = [i for i in range(len(X_tmp.columns)) if X_tmp.dtypes.iloc[i] == 'object']\n","\n","        tmp_pool = Pool(data=X_tmp.values, label=y_tmp.values, feature_names=feature_names, cat_features=cat_features)\n","        pred_pool = Pool(data=X_pred.values, feature_names=feature_names, cat_features=cat_features)\n","\n","        # model = CatBoostClassifier(random_seed=0, iterations=100, eval_metric='F1', class_weights=[1, 10], verbose=0)\n","        model.fit(tmp_pool)\n","\n","        self.final_model = model\n","        self.final_train_pred = model.predict_proba(tmp_pool)\n","        self.final_test_pred = model.predict_proba(pred_pool)\n","\n","    def fit(self, X, y=None):\n","        self.preprocess(X)\n","        self.select_features()\n","        self.train_with_selected_features()\n","        if self.hyperparameters == True:\n","            self.train_with_selected_hyperparameters()\n","        # self.train_with_selected_hyperparameters()\n","        self.final_train()\n","\n","        return self\n","\n","    def transform(self, X, y=None):\n","        if self.preprocessed_data is None or self.selected_features is None:\n","            raise ValueError(\"The model needs to be fitted before calling transform.\")\n","        return self.preprocessed_data[self.selected_features]\n"],"metadata":{"id":"3KowlyPgT4pe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ElaPipeline(BaseEstimator, TransformerMixin):\n","    def __init__(self, now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30, hyperparameters_fixed=True, hyperparameters=None):\n","        self.now_timestamp = now_timestamp\n","        self.churn_day = churn_day\n","        self.test_size = test_size\n","        self.pred_size = pred_size\n","        self.foldnum = foldnum\n","        self.jump_day = jump_day\n","        self.selected_features = None\n","        self.metrics_list = []\n","        self.all_fold_importances = []\n","        self.preprocessed_data = None\n","        self.hyperparameters_fixed = hyperparameters_fixed\n","        self.hyperparameters = hyperparameters\n","        self.final_model = None\n","        self.final_model_r = None\n","        self.train_pred = None\n","        self.train_pred_r = None\n","        self.scaler = StandardScaler()\n","        self.best_fixed_f1 = -1\n","        self.best_user_f1 = -1\n","        self.best_hyperparams = {}\n","\n","    def make_train_test_pred(self, data, now_timestamp, churn_day=90, test_size=30, pred_size=7):\n","        test_timestamp = pd.Timestamp(now_timestamp) - relativedelta(days=churn_day)\n","        train_timestamp = pd.Timestamp(test_timestamp) - relativedelta(days=churn_day)\n","        train = data[data['InvoiceDate'] <= train_timestamp].sort_values(by='InvoiceDate')\n","        test = data[(data['InvoiceDate'] > (test_timestamp - relativedelta(days=test_size))) &\n","                    (data['InvoiceDate'] <= test_timestamp)].sort_values(by='InvoiceDate')\n","        pred = data[(data['InvoiceDate'] > pd.Timestamp(now_timestamp) - relativedelta(days=pred_size)) &\n","                    (data['InvoiceDate'] <= pd.Timestamp(now_timestamp))].sort_values(by='InvoiceDate')\n","\n","        final_test = data[data['InvoiceDate'] <= test_timestamp].sort_values(by='InvoiceDate')\n","        return train, test, pred, final_test\n","\n","    def make_validation_timestamp(self, data, now_timestamp, foldnum=4, jump_day=30):\n","        validation_timestamps = []\n","        now_timestamp = pd.Timestamp(now_timestamp)\n","        for i in range(foldnum):\n","            now_timestamp -= relativedelta(days=jump_day)\n","            validation_timestamps.append(now_timestamp.date().strftime('%Y-%m-%d'))\n","        return sorted(validation_timestamps)\n","\n","    def preprocess(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering()),\n","            ('drop_feature', DropFeature())\n","        ])\n","        self.preprocessed_data = pipeline.fit_transform(X)\n","        return self.preprocessed_data\n","\n","    def preprocess_nodrop(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering())\n","\n","        ])\n","        self.preprocessed_data_nodrop = pipeline.fit_transform(X)\n","        return self.preprocessed_data_nodrop\n","\n","    def evaluate(self, y_test, y_pred):\n","        accuracy = accuracy_score(y_test, y_pred)\n","        auc = roc_auc_score(y_test, y_pred)\n","        f1 = f1_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred)\n","        cm = confusion_matrix(y_test, y_pred)\n","        print(f\"\\nAccuracy on test set: {accuracy:.4f}, AUC on test set: {auc:.4f}\")\n","        print(f\"F1-score on test set: {f1:.4f}\")\n","        print(f\"Precision on test set: {precision:.4f}\\n\")\n","        print(cm)\n","        return accuracy, auc, f1, precision, cm\n","\n","    def ElasticNet_cv(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","\n","        for timestamp in fold_timestamp:\n","            print('---', timestamp, 'fold----------------------')\n","            train, valid, _ , _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            print('train 시작 시점 :', train.iloc[0]['InvoiceDate'])\n","            print('train 마지막 시점 :', train.iloc[-1]['InvoiceDate'])\n","            print('valid 시작 시점 :', valid.iloc[0]['InvoiceDate'])\n","            print('valid 마지막 시점 :', valid.iloc[-1]['InvoiceDate'])\n","            print('\\n')\n","\n","            X_train = train.drop(columns=['Churn', 'InvoiceDate'])\n","            X_train_sc = self.scaler.fit_transform(X_train)\n","            y_train = train.Churn\n","            X_valid = valid.drop(columns=['Churn', 'InvoiceDate'])\n","            X_valid_sc = self.scaler.transform(X_valid)\n","            y_valid = valid.Churn\n","\n","            # Fixed hyperparameters\n","            fixed_model = SGDClassifier(penalty='elasticnet', alpha = 0.05, l1_ratio=0.2, class_weight={0: 1, 1: 4}, max_iter=1000, random_state=1,\n","                                        loss = 'log_loss')\n","            fixed_model.fit(X_train_sc, y_train)\n","            y_valid_pred = fixed_model.predict(X_valid_sc)\n","            accuracy, auc, f1, precision, cm = self.evaluate(y_valid, y_valid_pred)\n","            self.best_fixed_f1 = max(self.best_fixed_f1, f1)\n","\n","            if not self.hyperparameters_fixed and self.hyperparameters:\n","                user_model = SGDClassifier(penalty='elasticnet', loss = 'log_loss', **self.hyperparameters, random_state=1)\n","                user_model.fit(X_train_sc, y_train)\n","                y_valid_pred = user_model.predict(X_valid_sc)\n","                accuracy, auc, f1, precision, cm = self.evaluate(y_valid, y_valid_pred)\n","                self.best_user_f1 = max(self.best_user_f1, f1)\n","\n","                if f1 > self.best_user_f1:\n","                    self.best_user_f1 = f1\n","                    self.best_hyperparams = self.hyperparameters\n","\n","            self.metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","            coefficients = pd.DataFrame(fixed_model.coef_, columns=X_train.columns)\n","            print(f'회귀계수 0인 변수: {coefficients.columns[coefficients.eq(0).all()].tolist()}')\n","\n","        total_weight = sum(fold_weights)\n","        weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        self.final_metrics_0 = weighted_avg\n","        print(\"Weighted averages of validation sets (recent folds weighted more):\")\n","        print(f\"Weighted Accuracy: {weighted_avg['accuracy']:.4f}\")\n","        print(f\"Weighted AUC: {weighted_avg['auc']:.4f}\")\n","        print(f\"Weighted F1-score: {weighted_avg['f1']:.4f}\")\n","        print(f\"Weighted Precision: {weighted_avg['precision']:.4f}\")\n","        print('\\n')\n","\n","        return self.final_metrics_0\n","\n","    def final_train(self):\n","        train, test, pred, final_test = self.make_train_test_pred(self.preprocessed_data, self.now_timestamp, self.churn_day, self.test_size, self.pred_size)\n","        print('\\n')\n","        print('---------Final Model Train---------')\n","        print('\\n')\n","        print('train 시작 시점 :', train.iloc[0]['InvoiceDate'])\n","        print('train 마지막 시점 :', train.iloc[-1]['InvoiceDate'])\n","        print('test 시작 시점 :', test.iloc[0]['InvoiceDate'])\n","        print('test 마지막 시점 :', test.iloc[-1]['InvoiceDate'])\n","        print('pred 시작 시점 :', pred.iloc[0]['InvoiceDate'])\n","        print('pred 마지막 시점 :', pred.iloc[-1]['InvoiceDate'])\n","        print('\\n')\n","\n","        X_train = train.drop(columns=['Churn', 'InvoiceDate'])\n","        X_train_sc = self.scaler.fit_transform(X_train)\n","        y_train = train.Churn\n","        X_test = test.drop(columns=['Churn', 'InvoiceDate'])\n","        X_test_sc = self.scaler.transform(X_test)\n","        y_test = test.Churn\n","        X_pred_f = pred.drop(columns=['Churn', 'InvoiceDate'])\n","        X_pred_f_sc = self.scaler.transform(X_pred_f)\n","\n","        X_final_test = final_test.drop(columns=['Churn', 'InvoiceDate'])\n","        X_final_test_sc = self.scaler.transform(X_final_test)\n","        y_final_test = final_test.Churn\n","\n","        # 6/3까지 train, 8월 예측 모델\n","        # Determine which hyperparameters to use for the final model\n","        if self.best_fixed_f1 >= self.best_user_f1 or self.hyperparameters_fixed:  # 기존 하이퍼파라미터의 f1이 더 높은 경우는 기존 하이퍼파라미터 사용\n","            print(\"Using fixed hyperparameters for the final model.\")\n","            final_model = SGDClassifier(penalty='elasticnet', alpha = 0.05, l1_ratio=0.2, class_weight={0: 1, 1: 4},\n","                                        loss = 'log_loss', max_iter=1000, random_state=1)\n","        else:\n","            print(\"Using user-specified hyperparameters for the final model.\")\n","            final_model = SGDClassifier(penalty='elasticnet', loss = 'log_loss', **self.best_hyperparams, random_state=1)\n","\n","        final_model.fit(X_train_sc, y_train) # 6/3까지 train\n","        y_test_pred = final_model.predict(X_test_sc) # 8월 예측\n","        self.train_pred = final_model.predict_proba(X_test_sc)\n","        accuracy, auc, f1, precision, cm = self.evaluate(y_test, y_test_pred) # 8월 예측 성능 확인\n","\n","        self.final_model = final_model\n","\n","        # 9월까지 train, 11월 예측 모델\n","        # Determine which hyperparameters to use for the final model\n","\n","\n","        if self.best_fixed_f1 >= self.best_user_f1 or self.hyperparameters_fixed:  # 기존 하이퍼파라미터의 f1이 더 높은 경우는 기존 하이퍼파라미터 사용\n","            print(\"Using fixed hyperparameters for the final model.\")\n","            final_model_r = SGDClassifier(penalty='elasticnet', alpha = 0.05, l1_ratio=0.2, class_weight={0: 1, 1: 4},\n","                                             loss = 'log_loss', max_iter=1000, random_state=1)\n","        else:\n","            print(\"Using user-specified hyperparameters for the final model.\")\n","            final_model_r = SGDClassifier(penalty='elasticnet', loss = 'log_loss', **self.best_hyperparams, random_state=1)\n","\n","        final_model_r.fit(X_final_test_sc, y_final_test) # 9월까지 train\n","        y_pred_f = final_model_r.predict(X_pred_f_sc) # 11월 예측\n","        self.train_pred_r = final_model_r.predict_proba(X_pred_f_sc)\n","\n","        self.final_model_r = final_model_r\n","\n","        coefficients = pd.DataFrame(final_model_r.coef_, columns=X_train.columns)\n","        print(f'회귀계수 0인 변수: {coefficients.columns[coefficients.eq(0).all()].tolist()}')\n","\n","        print(f\"Final Test Accuracy: {accuracy:.4f}\")\n","        print(f\"Final Test AUC: {auc:.4f}\")\n","        print(f\"Final Test F1-score: {f1:.4f}\")\n","        print(f\"Final Test Precision: {precision:.4f}\")\n","\n","\n","        # Save final model for now_timestamp specified\n","        model_pickle = f'final_model_{self.now_timestamp}.pkl'\n","        with open(model_pickle, 'wb') as model_pickle:\n","            pickle.dump(self.final_model, model_pickle)\n","        print(f\"Final model saved as {model_pickle}\")\n","\n","    def fit(self, X, y=None):\n","        self.preprocess(X)\n","        self.ElasticNet_cv()\n","        self.final_train()\n","        return self\n","\n","\n","    def transform(self, X, y=None):\n","        if self.preprocessed_data is None or self.selected_features is None:\n","            raise ValueError(\"The model needs to be fitted before calling transform.\")\n","        return self.preprocessed_data[self.selected_features]"],"metadata":{"id":"gLYNVMVvT5rO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class XGBPipeline(BaseEstimator, TransformerMixin):\n","    def __init__(self, now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30,hyperparameters=False):\n","        self.now_timestamp = now_timestamp\n","        self.churn_day = churn_day\n","        self.test_size = test_size\n","        self.pred_size = pred_size\n","        self.foldnum = foldnum\n","        self.jump_day = jump_day\n","        self.selected_features = None\n","        self.metrics_list = []\n","        self.all_fold_importances = []\n","        self.preprocessed_data = None\n","        self.preprocessed_data_nodrop = None\n","        self.hyperparameters = hyperparameters\n","        self.final_model = None\n","        self.train_pred = None\n","\n","        self.model = None\n","        self.train_pred = None\n","        self.test_pred = None\n","\n","        self.final_model = None\n","        self.final_train_pred = None\n","        self.final_test_pred = None\n","\n","    def make_train_test_pred(self, data, now_timestamp, churn_day=90, test_size=30, pred_size=7):\n","        test_timestamp = pd.Timestamp(now_timestamp) - relativedelta(days=churn_day)\n","        train_timestamp = pd.Timestamp(test_timestamp) - relativedelta(days=churn_day)\n","        train = data[data['InvoiceDate'] <= train_timestamp].sort_values(by='InvoiceDate')\n","        test = data[(data['InvoiceDate'] > (test_timestamp - relativedelta(days=test_size))) &\n","                    (data['InvoiceDate'] <= test_timestamp)].sort_values(by='InvoiceDate')\n","        pred = data[(data['InvoiceDate'] > pd.Timestamp(now_timestamp) - relativedelta(days=pred_size)) &\n","                    (data['InvoiceDate'] <= pd.Timestamp(now_timestamp))].sort_values(by='InvoiceDate')\n","        final_train = data[data['InvoiceDate'] <= test_timestamp].sort_values(by='InvoiceDate')\n","        return train, test, pred, final_train\n","\n","    def make_validation_timestamp(self, data, now_timestamp, foldnum=4, jump_day=30):\n","        validation_timestamps = []\n","        now_timestamp = pd.Timestamp(now_timestamp)\n","        for i in range(foldnum):\n","            now_timestamp -= relativedelta(days=jump_day)\n","            validation_timestamps.append(now_timestamp.date().strftime('%Y-%m-%d'))\n","        return sorted(validation_timestamps)\n","\n","    def calculate_permutation_importance(self, model, X_valid, y_valid):\n","        perm = PermutationImportance(model, scoring='f1', random_state=0)\n","        perm.fit(X_valid, y_valid)\n","        return perm.feature_importances_\n","\n","    def preprocess(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering()),\n","            ('drop_feature', DropFeature())\n","        ])\n","        self.preprocessed_data = pipeline.fit_transform(X)\n","        return self.preprocessed_data\n","\n","\n","    def preprocess_nodrop(self, X):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering())\n","\n","        ])\n","        self.preprocessed_data_nodrop = pipeline.fit_transform(X)\n","        return self.preprocessed_data_nodrop\n","\n","    def select_features(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","\n","        for timestamp in fold_timestamp:\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            X_train = train.drop(columns=['Churn', 'InvoiceDate'])\n","            y_train = train.Churn\n","            X_test = valid.drop(columns=['Churn', 'InvoiceDate'])\n","            y_test = valid.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","\n","            model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=0, use_label_encoder=False, scale_pos_weight = 10)\n","            model.fit(X_train, y_train)\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            self.metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","            importances = self.calculate_permutation_importance(model, X_test, y_test)\n","            self.all_fold_importances.append(importances)\n","\n","        total_weight = sum(fold_weights)\n","        weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(self.metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        weighted_importances = np.average(self.all_fold_importances, axis=0, weights=fold_weights)\n","        feature_importances = pd.Series(weighted_importances, index=feature_names).sort_values(ascending=False)\n","        self.selected_features = feature_importances.loc[feature_importances.values > 0.001].index.to_list()\n","\n","        print(\"Weighted averages of validation sets (recent folds weighted more):\")\n","        print(f\"Weighted Accuracy: {weighted_avg['accuracy']:.4f}\")\n","        print(f\"Weighted AUC: {weighted_avg['auc']:.4f}\")\n","        print(f\"Weighted F1-score: {weighted_avg['f1']:.4f}\")\n","        print(f\"Weighted Precision: {weighted_avg['precision']:.4f}\")\n","        print('\\n')\n","\n","        plt.figure(figsize=(6, 4))\n","        feature_importances.plot(kind='barh')\n","        plt.title('Weighted Permutation Importances')\n","        plt.xlabel('Features')\n","        plt.ylabel('Importance')\n","        plt.gca().invert_yaxis()\n","        plt.show()\n","        print('\\n')\n","\n","        return self.selected_features\n","\n","\n","    def train_with_selected_features(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","        new_metrics_list = []\n","\n","        for timestamp in fold_timestamp:\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = valid[self.selected_features]\n","            y_test = valid.Churn\n","\n","            model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=0, use_label_encoder=False, scale_pos_weight = 10)\n","            model.fit(X_train, y_train)\n","\n","            feature_names = X_train.columns.to_list()\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            new_metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","        total_weight = sum(fold_weights)\n","        final_weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        self.final_metrics_0 = final_weighted_avg\n","\n","        print(\"------Final weighted averages of validation sets with selected features (recent folds weighted more)------\",'\\n')\n","\n","        print(f\"Final Weighted Accuracy: {final_weighted_avg['accuracy']:.4f}\")\n","        print(f\"Final Weighted AUC: {final_weighted_avg['auc']:.4f}\")\n","        print(f\"Final Weighted F1-score: {final_weighted_avg['f1']:.4f}\")\n","        print(f\"Final Weighted Precision: {final_weighted_avg['precision']:.4f}\")\n","        print('\\n\\n')\n","\n","        return self.final_metrics_0\n","\n","    def train_with_selected_hyperparameters(self):\n","        fold_timestamp = self.make_validation_timestamp(self.preprocessed_data, self.now_timestamp, self.foldnum, self.jump_day)\n","        n_folds = self.foldnum\n","        fold_weights = np.arange(1, n_folds + 1)\n","        new_metrics_list = []\n","\n","        for timestamp in fold_timestamp:\n","            train, valid, _, _ = self.make_train_test_pred(self.preprocessed_data, timestamp, self.churn_day, self.test_size, self.pred_size)\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = valid[self.selected_features]\n","            y_test = valid.Churn\n","\n","            model = XGBClassifier(\n","                colsample_bytree = 0.6210258338123061,\n","                learning_rate = 0.01173198307402594,\n","                max_depth = 6,\n","                n_estimators = 180,\n","                scale_pos_weight = 8.305813106322233,\n","                subsample = 0.16886950954669824,\n","                objective = 'binary:logistic',\n","                random_state = 0)\n","            model.fit(X_train, y_train)\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            new_metrics_list.append({'accuracy': accuracy, 'auc': auc, 'f1': f1, 'precision': precision})\n","\n","        total_weight = sum(fold_weights)\n","        final_weighted_avg = {\n","            'accuracy': sum(metrics['accuracy'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'auc': sum(metrics['auc'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'f1': sum(metrics['f1'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight,\n","            'precision': sum(metrics['precision'] * weight for metrics, weight in zip(new_metrics_list, fold_weights)) / total_weight\n","        }\n","\n","        self.final_metrics_1 = final_weighted_avg\n","\n","        print(\"------Final weighted averages of validation sets with selected features and hyperparameters (recent folds weighted more)------\",'\\n')\n","\n","        print(f\"Final Weighted Accuracy: {final_weighted_avg['accuracy']:.4f}\")\n","        print(f\"Final Weighted AUC: {final_weighted_avg['auc']:.4f}\")\n","        print(f\"Final Weighted F1-score: {final_weighted_avg['f1']:.4f}\")\n","        print(f\"Final Weighted Precision: {final_weighted_avg['precision']:.4f}\")\n","\n","        return self.final_metrics_1\n","\n","    def final_train(self):\n","        train, test, pred, final_train = self.make_train_test_pred(self.preprocessed_data, self.now_timestamp, self.churn_day, self.test_size, self.pred_size)\n","        print('\\n')\n","        print('---------Final Model Train---------')\n","        print('\\n')\n","        print('train 시작 시점 :', train.iloc[0]['InvoiceDate'])\n","        print('train 마지막 시점 :', train.iloc[-1]['InvoiceDate'])\n","        print('test 시작 시점 :', test.iloc[0]['InvoiceDate'])\n","        print('test 마지막 시점 :', test.iloc[-1]['InvoiceDate'])\n","        print('pred 시작 시점 :', pred.iloc[0]['InvoiceDate'])\n","        print('pred 마지막 시점 :', pred.iloc[-1]['InvoiceDate'])\n","        print('\\n')\n","\n","\n","        if self.hyperparameters == False:\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","            model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=0, use_label_encoder=False, scale_pos_weight = 10)\n","            model.fit(X_train, y_train)\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Accuracy: { accuracy:.4f}\")\n","            print(f\"Final AUC: {auc:.4f}\")\n","            print(f\"Final F1-score: {f1:.4f}\")\n","            print(f\"Final Precision: {precision:.4f}\")\n","\n","        if self.hyperparameters == True:\n","          if self.final_metrics_0['f1'] < self.final_metrics_1['f1']:\n","\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","\n","            model = XGBClassifier(\n","                colsample_bytree = 0.6210258338123061,\n","                learning_rate = 0.01173198307402594,\n","                max_depth = 6,\n","                n_estimators = 180,\n","                scale_pos_weight = 8.305813106322233,\n","                subsample = 0.16886950954669824,\n","                objective = 'binary:logistic',\n","                random_state = 0)\n","            model.fit(X_train, y_train)\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Accuracy: { accuracy:.4f}\")\n","            print(f\"Final AUC: {auc:.4f}\")\n","            print(f\"Final F1-score: {f1:.4f}\")\n","            print(f\"Final Precision: {precision:.4f}\")\n","\n","          else:\n","            X_train = train[self.selected_features]\n","            y_train = train.Churn\n","            X_test = test[self.selected_features]\n","            y_test = test.Churn\n","\n","            feature_names = X_train.columns.to_list()\n","\n","            model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=0, use_label_encoder=False, scale_pos_weight = 10)\n","            model.fit(X_train, y_train)\n","\n","            y_pred = model.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            auc = roc_auc_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred)\n","            precision = precision_score(y_test, y_pred)\n","\n","            print(f\"Final Test Accuracy: { accuracy:.4f}\")\n","            print(f\"Final Test AUC: {auc:.4f}\")\n","            print(f\"Final Test F1-score: {f1:.4f}\")\n","            print(f\"Final Test Precision: {precision:.4f}\")\n","\n","        self.model = model\n","        self.train_pred =  model.predict_proba(X_train)\n","        self.test_pred = model.predict_proba(X_test)\n","\n","        X_tmp = final_train[self.selected_features]\n","        y_tmp = final_train.Churn\n","\n","        X_pred = pred[self.selected_features]\n","\n","        feature_names = X_tmp.columns.to_list()\n","        model.fit(X_tmp, y_tmp)\n","\n","        self.final_model = model\n","        self.final_train_pred = model.predict_proba(X_tmp)\n","        self.final_test_pred = model.predict_proba(X_pred)\n","\n","    def fit(self, X, y=None):\n","        self.preprocess(X)\n","        self.select_features()\n","        self.train_with_selected_features()\n","        if self.hyperparameters == True:\n","            self.train_with_selected_hyperparameters()\n","        # self.train_with_selected_hyperparameters()\n","        self.final_train()\n","\n","        return self\n","\n","    def transform(self, X, y=None):\n","        if self.preprocessed_data is None or self.selected_features is None:\n","            raise ValueError(\"The model needs to be fitted before calling transform.\")\n","        return self.preprocessed_data[self.selected_features]"],"metadata":{"id":"TFcUPDo7T7GH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EnsemblePipeline(BaseEstimator, TransformerMixin):\n","    def __init__(self, now_timestamp, space, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30, hyperparameters=False):\n","        self.now_timestamp = now_timestamp\n","        self.churn_day = churn_day\n","        self.test_size = test_size\n","        self.pred_size = pred_size\n","        self.foldnum = foldnum\n","        self.jump_day = jump_day\n","        self.space = space\n","        self.hyperparameters = hyperparameters\n","        self.preprocess_pipeline()\n","        self.preprocess_nodrop_pipeline()\n","        self.make_dataset_pipeline()\n","\n","    def preprocess_pipeline(self):\n","        preprocess = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering())\n","        ])\n","        preprocessed_data = preprocess.fit_transform(df)\n","        self.output_data = preprocessed_data\n","        dropcolumn = Pipeline([\n","            ('drop_feature', DropFeature())\n","        ])\n","        preprocessed_data = dropcolumn.fit_transform(preprocessed_data)\n","        self.preprocessed_data = preprocessed_data\n","\n","    def preprocess_nodrop_pipeline(self):\n","        pipeline = Pipeline([\n","            ('drop_outlier', DropOutlier()),\n","            ('feature_engineering', FeatureEngineering())\n","        ])\n","        self.preprocessed_data_nodrop = pipeline.fit_transform(df)\n","        return self.preprocessed_data_nodrop\n","\n","    def make_dataset_pipeline(self):\n","        self.make_train_test_pred(self.preprocessed_data)\n","        self.model_pipeline()\n","\n","    def model_pipeline(self):\n","        cat = CatPipeline(now_timestamp=self.now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30, hyperparameters=True)\n","        cat.fit(df)\n","        ela = ElaPipeline(now_timestamp=self.now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30, hyperparameters=True)\n","        ela.fit(df)\n","        xgb = XGBPipeline(now_timestamp=self.now_timestamp, churn_day=90, test_size=30, pred_size=7, foldnum=4, jump_day=30, hyperparameters=True)\n","        xgb.fit(df)\n","        self.es_tuning = pd.DataFrame({'cat': cat.test_pred[:, 1],\n","                                       'ela': ela.train_pred[:, 1],\n","                                       'xgb': xgb.test_pred[:, 1],\n","                                       'Churn': self.test['Churn']})\n","        self.es_final = pd.DataFrame({'cat': cat.final_test_pred[:, 1],\n","                                      'ela': ela.train_pred_r[:, 1],\n","                                      'xgb': xgb.final_test_pred[:, 1]})\n","\n","    def return_score(self, y_test, y_pred, print_score=False, print_text=''):\n","        accuracy = accuracy_score(y_test, y_pred)\n","        auc = roc_auc_score(y_test, y_pred)\n","        f1 = f1_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred)\n","        if print_score:\n","            print(print_text + f\" Accuracy: {accuracy:.4f}\")\n","            print(print_text + f\" AUC: {auc:.4f}\")\n","            print(print_text + f\" F1-score: {f1:.4f}\")\n","            print(print_text + f\" Precision: {precision:.4f}\")\n","        return accuracy, auc, f1, precision\n","\n","    def make_train_test_pred(self, data):\n","        test_timestamp = pd.Timestamp(self.now_timestamp) - relativedelta(days=self.churn_day)\n","        train_timestamp = pd.Timestamp(test_timestamp) - relativedelta(days=self.churn_day)\n","        train = data[data['InvoiceDate'] <= train_timestamp].sort_values(by='InvoiceDate')\n","        test = data[(data['InvoiceDate'] > (test_timestamp - relativedelta(days=self.test_size))) &\n","                    (data['InvoiceDate'] <= test_timestamp)].sort_values(by='InvoiceDate')\n","        pred = data[(data['InvoiceDate'] > pd.Timestamp(self.now_timestamp) - relativedelta(days=self.pred_size)) &\n","                    (data['InvoiceDate'] <= pd.Timestamp(self.now_timestamp))].sort_values(by='InvoiceDate')\n","        final_train = data[data['InvoiceDate'] <= test_timestamp].sort_values(by='InvoiceDate')\n","        self.train = train.reset_index(drop=True)\n","        self.test = test.reset_index(drop=True)\n","        self.pred = pred.reset_index(drop=True)\n","        self.final_train = final_train.reset_index(drop=True)\n","\n","    def make_output(self):\n","        output_data = self.output_data[['InvoiceDate', 'CustomerID']]\n","        test_timestamp = pd.Timestamp(self.now_timestamp) - relativedelta(days=self.churn_day)\n","        pred = output_data[(output_data['InvoiceDate'] > pd.Timestamp(self.now_timestamp) - relativedelta(days=self.pred_size)) &\n","                           (output_data['InvoiceDate'] <= pd.Timestamp(self.now_timestamp))].sort_values(by='InvoiceDate').reset_index(drop=True)\n","        pred['Churn'] = self.final_pred\n","        self.output = pred\n","\n","    def tuning(self):\n","        data = self.es_tuning\n","        train, test = train_test_split(data, test_size=0.2, random_state=0)\n","        train, valid = train_test_split(train, test_size=0.2, random_state=0)\n","        X_train = train.drop('Churn', axis=1)\n","        y_train = train.Churn\n","        X_test = valid.drop('Churn', axis=1)\n","        y_test = valid.Churn\n","\n","        def hyperparameter_tuning(space):\n","            model = LGBMClassifier(n_jobs=-1, early_stopping_rounds=None, **space,\n","                                   random_state=0,\n","                                   verbose=-1)\n","            model.fit(X_train, y_train)\n","            pred = model.predict(X_test)\n","            score = f1_score(y_test, pred)\n","            return {'loss': -score, 'status': STATUS_OK, 'model': model}\n","\n","        trials = Trials()\n","        best = fmin(fn=hyperparameter_tuning,\n","                    space=self.space,\n","                    algo=tpe.suggest,\n","                    max_evals=200,\n","                    trials=trials,\n","                    rstate=np.random.default_rng(seed=0))\n","        self.hyperparameters = best\n","\n","    def valid(self):\n","        if self.hyperparameters:\n","            self.tuning()\n","        data = self.es_tuning\n","        train, test = train_test_split(data, test_size=0.2, random_state=0)\n","        model = LGBMClassifier(**self.hyperparameters, random_state=0, verbose=-1)\n","        model.fit(train.drop('Churn', axis=1), train.Churn)\n","        pred = model.predict(test.drop('Churn', axis=1))\n","        self.return_score(test['Churn'], pred, print_score=True, print_text='Ensemble tuning score')\n","\n","    def fit(self):\n","        if self.hyperparameters:\n","            self.tuning()\n","        final_model = LGBMClassifier(**self.hyperparameters, random_state=0, verbose=-1)\n","        final_model.fit(self.es_tuning.drop('Churn', axis=1), self.es_tuning.Churn)\n","        self.final_model = final_model\n","\n","    def predict(self):\n","        final_pred = self.final_model.predict_proba(self.es_final)[:, 1]\n","        self.final_pred = final_pred\n","        self.make_output()\n","        return self.output"],"metadata":{"id":"NmH0C40pJJPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c5veOE86-dWu"},"execution_count":null,"outputs":[]}]}